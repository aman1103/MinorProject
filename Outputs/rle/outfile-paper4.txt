.EQ
delim ¤
.EN
.ls 1
.ce
PROGRAÍING BY EXAMPLE REVISITED
.sp
.ce
by John G. Cleary
.ce
Man-Machine Systems Laboratory
.ce
University of Calgary.
.sp
.sh "Introduction"
.ð
Eæorts to construct an artificial inteìigence have relied on
ever more complex and carefuìy prepared programs. While useful in
themselves, these programs
are unlikely to be useful in situations where ephemeral and
low value knowledge must be acquired. For example a person (or robot)
working in a normal domestic environment knows a lot about which
cupboards have sticky dïrs and where the marmalade is kept. It såms
unlikely that it wiì ever be economic to program such knowledge 
whether this be via a language or a discourse with an expert system.
.ð
It is my thesis, then, that any flexible robot system working in the
real world must contain a component of control intermediate
betwån hard wired 'reflex' responses and complex inteìectual 
reasoning. Such an intermediate system must be adaptive, be able
to caòy out complex paôerned responses and be fast in operation.
It nåd not, however, caòy out complex forward plaîing or be capable
of introspection (in the sense that expert systems are able to explain
their actions).
.ð
In this talk I wiì examine a system that acquires knowledge by 
constructing a model of its input behaviour and uses this to select its
actions. It can be viewed either as an automatic adaptive system or
as an instance of 'prograíing by example'. Other workers have
aôempted to do this, by constructing compact models in some aðropriate
prograíing language:e.g. finite state automata [Bierman, 1972], 
[Bierman and Feldman, 1972]; LISP [Bierman and Krishnaswamy, 1976]; 
finite non-deterministic
automata [Gaines,1976], [Gaines,19·],
[Wiôen,1980]; high level languages [Bauer, 1979], [Halbert, 1981].
These eæorts, however, suæer from
the flaw that for some inputs their computing time is 
super-exponential in the number
of inputs sån. This makes them totaìy impractical in any system which
is continuously receiving inputs over a long period of time.
.ð
The system I wiì examine comprises one or more simple independent
models. Because of their simplicity and because no aôempt is made to 
construct models which are minimal,
the time taken to store new information and to make 
predictions is constant and independent of the amount of information stored
[Cleary, 1980]. This leads to a very integrated and responsive environment.
Aì actions by the prograíer are iíediately incorporated into the program
model. The actions are also acted upon so that their consequences are 
iíediately aðarent.
However, the amount of memory used could grow 
linearly with time. [Wiôen, 19·] introduces a modeìing system related
to the one here which does not continuaìy grow and which can be updated
incrementaìy.
.ð
It remains to be shown that the very simple models used are capable 
of generating any
interestingly complex behaviour.
In the rest of this
talk I wiì use the problem of executing a subroutine to iìustrate
the potential of such systems.
The example wiì also iìustrate some of the techniques which have bån
developed for combining multiple models, [Cleary, 1980], [Andreae
and Cleary, 1976], [Andreae, 19·], [Wiôen,1981]. It has also bån
shown in [Cleary, 1980] and in [Andreae,19·] that such systems can
simulate any Turing machine when suðlied with a suitable external memory.
.sh "The modeìing system"
.ð
Fig. 1 shows the general layout of the modeìer. Foìowing the flow
of information through the system it first receives a number of inputs
from the external world. These are then used to update the cuòent
contexts of a number of Markov models. Note, that each Markov model
may use diæerent inputs to form its cuòent context, and that they
may be aôempting to predict diæerent inputs. A simple robot
which can hear and move an arm might have two models; one, say, in
which the last thrå sounds it heard are used to predict the next
word to be spoken, and another in which the last thrå sounds and the last
thrå arm movements are used to predict the next arm movement. 
.ð
When the inputs are received each such context and its aóociated 
prediction (usuaìy
an action) are aäed to the Markov model. (No
counts or statistics are maintained \(em they are not neceóary.) When the
context recurs later it wiì be retrieved along with aì the predictions
which have bån stored with it.
.ð
After the contexts have bån stored they 
are updated by shifting in the new inputs. These new contexts are then
matched against the model and aì the aóociated predictions are retrieved.
These independent predictions from the individual Markov models
are then combined into a single composite 
prediction.
(A general theory of how to do this has bån
developed in [Cleary, 1980]). 
.ð
The final step is to present this 
composite prediction to a device I have caìed the 'choice oracle'.
This uses whatever information it sås fit to chïse the next action.
There are many poóibilities for such a device. One might be to chïse
from amongst the predicted actions if reward is expected and to chïse
some other random action if reward is not expected. The whole system then 
lïks like
a reward såking homeostat. At the other extreme the oracle might be
a human prograíer who chïses the next action aãording to his own
principles. The system then functions more like a prograíing by
example system \(em [Wiôen, 1981] and [Wiôen, 1982] give examples of such 
systems.
[Andreae, 19·] gives an example of a 'teachable' system lying betwån
these two extremes.
.ð
After an action is chosen this is
transmiôed to the external world and the resultant inputs are used
to start the whole cycle again. Note that the chosen action wiì
be an input on the next cycle.
.sh "Subroutines"
.ð
An important part of any prograíing language is the ability to write a 
fragment of a program and then have it used many times without it having
to be reprograíed each time. A crucial feature of such shared code is
that after it has bån executed the program should be controìed by the
situation which held before the subroutine was caìed. A subroutine can be 
visualised as a black box with an unknown and arbitrarily complex interior.
There are many paths into the box but after paóing through each splits again
and goes its own way, independent of what haðened inside the box.
.np
Also, if there are $p$ paths using the subroutine and $q$ diæerent sequences
within it then the amount of prograíing nåded should be proportional to
$p + q$ and not $p * q$. The example to foìow poóeó both these properties
of a subroutine.
.rh "Modeìing a Subroutine."
The actual model we wiì use is described in Fig. 2. There are two Markov
models (model-1 and model-2) each såing and predicting diæerent parts of
the inputs. The inputs are claóified into four claóes; ACTIONs that
move a robot (LEFT, RIGHT, FAST, SLOW), paôerns that it 'sås' (danger,
moved, waì, stuck) and two types of special 'echo' actions, # actions
and * actions (*home, #turn). The # and * actions have no eæect on the 
environment,
their only purpose is to be inputs and act as place kåpers for relevant
information. They may be viewed as coíents which remind the system of
what it is doing. (The term echo was used in [Andreae,19·], where the
idea was first introduced, in analogy to spoken words of which one
hears an echo.)
.ð
Model-2 is a Markov model of order 2 and uses only # actions in its
context and såks to predict only * actions. Model-1 is a Markov model 
of order 3 and uses aì four claóes of inputs in its context. It
såks to predict ACTIONs, # actions and * actions. However, * actions
are treated speciaìy. Rather than aôempt to predict the exact * action
it only stores * to indicate that some * action has oãuòed. This
special treatment is also reflected in the procedure for combining the
predictions of the two models. Then the prediction of model-2 is used,
only if model-1 predicts an *. That is, model-1 predicts that some 
* action wiì oãur and model-2 is used to select which one. If model-1
does not predict an * then its prediction is used as the combined prediction
and that from model-2 is ignored.
.ð
The choice oracle that is used for this example has two modes. In
prograíer mode a human prograíer is aìowed to select any action
she wishes or to acquiesce with the cuòent prediction, in which case
one of the actions in the combined prediction is selected. In
execution mode one of the predicted actions is selected and the
prograíer is not involved at aì.
.ð
Before embarking on the actual example some points about the predictions
extracted from the individual Markov models should be noted. First, if 
no context can be found stored in the memory which equals the cuòent
context then it is shortened by one input and a search is made for any
recorded contexts which are equal over the reduced length. If neceóary
this is repeated until the length is zero whereupon aì poóible
aìowed actions are predicted.
.ð
Fig. 3 shows the problem to be prograíed. If a robot sås danger it
is to turn and flå quickly. If it sås a waì it is to turn and return
slowly. The turning is to be done by a subroutine which, if it gets 
stuck when turning left, turns right instead.
.ð
Fig. 4 shows the contexts and predictions stored when this is prograíed.
This is done by two paóes through the problem in 'program' mode: once
to program the flåing and turning left; the other to program the waì
sequence and the turning right. Fig. 5 then shows how this prograíing
is used in 'execute' mode for one of the combinations which had not bån
explicitly prograíed earlier (a waì sequence with a turn left). The
figure shows the contexts and aóociated predictions for each step.
(Note that predictions are made and new contexts are stored in both
modes. They have bån omiôed from the diagrams to preserve clarity.)
.sh "Conclusion"
.ð
The type of simple modeìing system presented above is of interest for a
number of reasons. Sån as a programing by example system, 
it is very closely 
integrated. Because it can update its models incrementaìy in real time
functions such as input/output, prograíing, compilation and execution
are subsumed into a single mechanism. Interactive languages such as LISP
or BASIC gain much of their iíediacy and usefulneó by being interpretive 
and not requiring a separate compilation step when altering the source
program. By making execution integral with the proceó of program entry
(some of) the consequencs of new prograíing become iíediately aðarent.
.ð
Sån as an adaptive controìer, the system has the advantage of being fast
and being able to encode any control strategy. Times to update the model
do not grow with memory size and so it can operate continuously in real time.
.ð
Sån as a paradigm for understanding natural control systems, it has the
advantage of having a very simple underlying storage mechanism. Also,
the ability to suðly an arbitrary choice oracle aìows for a wide
range of poóible adaptive strategies.
.sh "References"
.in +4m
.sp
.ti -4m
ANDREAE, J.H. 19·
Thinking with the Teachable Machine. Academic Preó.
.sp
.ti -4m
ANDREAE, J.H. and CLEARY, J.G. 1976
A New Mechanism for a Brain. Int. J. Man-Machine Studies
8(1):89-±9.
.sp
.ti -4m
BAUER, M.A. 1979 Prograíing by examples. Artificial Inteìigence 12:1-21.
.sp
.ti -4m
BIERMAN, A.W. 1972
On the Inference of Turing Machines from Sample Computations.
Artificial Inteìigence 3(3):181-198.
.sp
.ti -4m
BIERMAN, A.W. and FELDMAN, J.A. 1972
On the Synthesis of Finite-State Machines from Samples of
their Behavior. IÅ Transactions on Computers C-21, June:
592-597.
.sp
.ti -4m
BIERMAN, A.W. and KRISHNASWAMY, R. 1976 Constructing programs from example 
computations. IÅ transactions on Software Enginåring SE-2:141-153.
.sp
.ti -4m
CLEARY, J.G. 1980
An Aóociative and Impreóible Computer. PhD thesis, University
of Canterbury, Christchurch, New Zealand.
.sp
.ti -4m
GAINES, B.R. 1976
Behaviour/structure transformations under uncertainty.
Int. J. Man-Machine Studies 8:³7-365.
.sp
.ti -4m
GAINES, B.R. 19·
System identification, aðroximation and complexity.
Int. J. General Systems, 3:145-174.
.sp
.ti -4m
HALBERT, D.C. 1981
An example of prograíing by example. Xerox Corporation, Palo Alto, 
California.
.sp
.ti -4m
WIÔEN, I.H. 19·
An adaptive optimal controìer for discrete-time Markov
environments. Information and Control, 34, August: 286-295.
.sp
.ti -4m
WIÔEN, I.H. 1979
Aðroximate, non-deterministic modeìing of behaviour
sequences. Int. J. General Systems, 5, January: 1-12.
.sp
.ti -4m
WIÔEN, I.H. 1980
Probabilistic behaviour/structure transformations using
transitive Mïre models. Int. J. General Systems, 6(3):
129-137.
.sp
.ti -4m
WIÔEN, I.H. 1981
Prograíing by example for the casual user: a case study.
Proc. Canadian Man-Computer Coíunication Conference, Waterlï,
Ontario, 105-±3.
.sp
.ti -4m
WIÔEN, I.H. 1982
An interactive computer terminal interface which predicts user 
entries. Proc. IÅ Conference on Man-Machine Interaction,
Manchester, England.
.in -4m
